<!doctype html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
   <link rel="stylesheet" href="/regional-spanish-models-talk-2022/libs/katex/katex.min.css">
   
  

  <link href="/regional-spanish-models-talk-2022/css/franklin.css" rel="stylesheet">
<link href="/regional-spanish-models-talk-2022/css/vela.css" rel="stylesheet">
<link href="/regional-spanish-models-talk-2022/css/mystyle.css" rel="stylesheet">

<script src="/regional-spanish-models-talk-2022/libs/vela/jquery.min.js"></script>

<link rel="icon" href="/regional-spanish-models-talk-2022/assets/favicon.png">


  <title>Regional Spanish Models</title>
</head>
<body>
<div class="main-nav slideout-menu slideout-menu-left" id="menu">
  <div class="flex-container">
    <span class="sidebar-brand">
      <h3 style='font-size: 20px; padding: 1em;'>Regional Spanish Resources</h3>
    </span>
  </div> <!-- class="flex-container" -->

  <nav class="sidebar-nav">
    <ul class="metismenu" id="metismenu" >
      <li><a href="/regional-spanish-models-talk-2022/index.html">Introducción</a></li>
      <li><a href="/regional-spanish-models-talk-2022/corpora/">Corpus</a></li>
      <li><a href="/regional-spanish-models-talk-2022/recursos-lexicos/">Recursos léxicos</a></li>
      <li><a href="/regional-spanish-models-talk-2022/recursos-semanticos/">Word embeddings</a></li>
      <li><a href="/regional-spanish-models-talk-2022/recursos-modelos-de-lenguaje/">Modelos de lenguaje</a></li>
      <li><a href="/regional-spanish-models-talk-2022/conclusiones/">Conclusiones y trabajo a futuro</a></li>
    </ul>
  </nav>

  <span class="sidebar-brand">
    <h3 style='font-size: 20px; padding: 1em;'>
  <strong>Eric S. Téllez</strong> – CONACyT - CICESE - INFOTEC <a href="">email:eric.tellez@ieee.org</a>
  </h3>
  </span>

</div> <!-- main nav menu -->

<main id="panel" class="slidout-panel slideout-panel-left">
  <div class="toggle-button hamburger hamburger--spin">
    <div class="hamburger-box">
      <div class="hamburger-inner"></div>
    </div>
  </div>
  <h1 class="page title">Language models</h1>
  <hr>



<!-- Content appended here -->
<div class="franklin-content"><h1 id="modelos_de_lenguaje"><a href="#modelos_de_lenguaje" class="header-anchor">Modelos de lenguaje</a></h1>
<ul>
<li><p><a href="https://ingeotec.github.io/regional-spanish-models/">Recursos</a></p>
</li>
<li><p><a href="https://github.com/INGEOTEC/regional-spanish-models">Repositorio</a></p>
</li>
</ul>
<p>Los modelos de lenguaje, <em>Language Models &#40;LM&#41;</em>, son más sofisticados que los word-embeddings ya que para determinar el vector de una palabra considera el contexto de la misma, y muchos modelos también son capaces de generar apartir de lo aprendido.</p>
<div class="warn"><strong>BERT</strong> es un modelo de lenguaje que básicamente rompió el paradigma. Consiste en una serie de <em>encoders</em> que generan embeddings para cada palabra dependiendo de su contexto. El entrenamiento usa un lenguaje de enmascarado, Masked Language Model &#40;MLM&#41;. Cada sentencia enmascará tokens de manera aleatoría &#40;se enmascaran 15&#37; de los tokens&#41;. También se entrena para predicción de la siguiente frase.</div>
<h2 id="recursos_computacionales_y_necesidad_de_datos"><a href="#recursos_computacionales_y_necesidad_de_datos" class="header-anchor">Recursos computacionales y necesidad de datos</a></h2>
<ul>
<li><p>Los modelos de lenguaje requieren una gran cantidad de datos, solo generamos recursos con MLM sobre AR, CL, CO, MX, ES, UY, VE, y US, i.e., los más grandes. También se utiliza la unión de todos.</p>
</li>
<li><p>Todos los modelos tienen series de dos encoders con cuatro cabezas de atención cada una y una salida de 512 dimensiones por embedding</p>
</li>
<li><p>Corresponde al <em>small-size</em> del BERT original, y es lo que actualmente podemos con los recursos que contamos en un tiempo <em>pagable</em> &#40;usamos una estanción de trabajo NVIDIA TITAN RTX con 24 GB cada una&#41;</p>
</li>
<li><p>Nombramos a nuestro modelo BILMA por <em>Bert In Latin America</em>.</p>
</li>
<li><p>Usamos un <em>learning rate</em> de <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><msup><mn>0</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup></mrow><annotation encoding="application/x-tex">10^{-5}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord">1</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">−</span><span class="mord mtight">5</span></span></span></span></span></span></span></span></span></span></span></span> con el optimizador Adam &#40;usamos tensorflow 2 y Keras&#41;.</p>
</li>
<li><p>Los modelos para CL, UY, VE, y US se entrenaron con 3 epocas y AR, CO, MX, y ES por solo una dado los tamaños de los corpus.</p>
</li>
</ul>
<h3 id="como_se_compara_bilma_con_los_word-embeddings"><a href="#como_se_compara_bilma_con_los_word-embeddings" class="header-anchor">Como se compara BILMA con los word-embeddings</a></h3>
<div style="; padding: 0.5em; margin: 0.5em; text-align: center;"><img src="https://github.com/sadit/regional-spanish-models-talk-2022/raw/main/src/figs/fig-bilma-cls.png" alt="" style="width: 100%; left-margin: 0; padding: 0;" />
<div style="text-align: center; width: 100%;"> \textit{Accuracy} en predicción de Emoji-15 -- \textit{tuneado}</div>
</div>
<div class="warn"><ul>
<li><p>Se <em>tuneó</em> el modelo BILMA para predecir emoticones añadiendo dos capas lineales a los embeddings de inicio, por lo que se puede ver que se predice independiente de la posición. </p>
</li>
<li><p>Tuneo con 90&#37;-10&#37; del training set de la región hasta que el <em>accuracy</em> convergió.</p>
</li>
<li><p>Se evaluó con test regional.</p>
</li>
<li><p>Observe que es una matriz de modelos pre-entrenados y tuneos.</p>
</li>
<li><p>Los resultados en general son muy similares a los modelos de fastText, pero, los modelos BILMA pueden hacer más cosas...</p>
</li>
</ul></div>
<h3 id="usando_bilma_para_completar_frases_mediante_máscaras"><a href="#usando_bilma_para_completar_frases_mediante_máscaras" class="header-anchor">Usando BILMA para completar frases &#40;mediante máscaras&#41;</a></h3>
<div style="; padding: 0.5em; margin: 0.5em; text-align: center;"><img src="https://github.com/sadit/regional-spanish-models-talk-2022/raw/main/src/figs/fig-bilma-mlm.png" alt="" style="width: 100%; left-margin: 0; padding: 0;" />
<div style="text-align: center; width: 100%;"> \textit{Accuracy} en la tarea MLM para el test</div>
</div>
<h4 id="ejemplos_de_completar_frases_no_vistas_sobre_recursos_regionales"><a href="#ejemplos_de_completar_frases_no_vistas_sobre_recursos_regionales" class="header-anchor">Ejemplos de completar frases &#40;no vistas&#41; sobre recursos regionales</a></h4>
<div style="; padding: 0.5em; margin: 0.5em; text-align: center;"><img src="https://github.com/sadit/regional-spanish-models-talk-2022/raw/main/src/figs/bilma-mlm-table.png" alt="" style="width: 100%; left-margin: 0; padding: 0;" />
<div style="text-align: center; width: 100%;"> Completando frases -- minería de opinión</div>
</div>

  <div style="width: 100%; background-color: rgb(229, 195, 182); border: solid rgb(36, 36, 37)  1px; padding: 0.5em; margin-top: 1em; text-align: center;">
    <span> <a href="/regional-spanish-models-talk-2022/index.html">Introducción</a></span> -
    <span> <a href="/regional-spanish-models-talk-2022/corpora/">Corpus</a></span> -
    <span><a href="/regional-spanish-models-talk-2022/recursos-lexicos/">Recursos léxicos</a></span> -
    <span><a href="/regional-spanish-models-talk-2022/recursos-semanticos/">Word embeddings</a></span> -
    <span><a href="/regional-spanish-models-talk-2022/recursos-modelos-de-lenguaje/">Modelos de lenguaje</a></span> -
    <span> <a href="/regional-spanish-models-talk-2022/conclusiones/">Conclusiones</a></span>
  </div>

<div class="page-foot">
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Eric S. Tellez <eric.tellez@infotec.mx>. Last modified: January 26, 2023.
    Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
</div>
</div><!-- CONTENT ENDS HERE -->
  </main> <!-- end of id=main -->
  <script src="/regional-spanish-models-talk-2022/libs/vela/metisMenu.min.js"></script>
  <script src="/regional-spanish-models-talk-2022/libs/vela/slideout.min.js"></script>
  
    



  
  
  
</body>
</html>
